{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Calculando métodos e métricas considerando a classificação binária do dataset de creditcardfraud como operações fraudulentas ou não."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "og_df_pre = pd.read_csv(\"/mnt/78C91DD876D41E26/GitHub/IA/EP/creditcard.zip\")\n",
    "og_df_norm = pd.read_csv(\"/mnt/78C91DD876D41E26/GitHub/IA/EP/creditcard_norm.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "### CROSS VALIDATIONE EXAMPLE ###\n",
    "###\n",
    "\n",
    "# from sklearn import model_selection as ms\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn import svm\n",
    "\n",
    "# cols = df_pre.columns.tolist()\n",
    "# classe = cols.pop(2)\n",
    "\n",
    "# # Usando apenas 1000 linhas\n",
    "# a = df_pre.loc[1:1000,cols]\n",
    "# b = df_pre[classe].iloc[0:1000]\n",
    "\n",
    "# kf = ms.KFold(10)\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# X = a.to_numpy()\n",
    "# y = b.to_numpy()\n",
    "# clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "# scores = cross_val_score(clf, X, y, cv=10, n_jobs=-1)\n",
    "# print(scores)\n"
   ]
  },
  {
   "source": [
    "## Separando as classes do dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Colunas para separar o dataset da classe\n",
    "cols = og_df_pre.columns.tolist()\n",
    "classe = cols.pop(2)\n",
    "\n",
    "num_amostra = 10000\n",
    "df_pre = og_df_pre.sample(num_amostra, random_state=42)\n",
    "df_norm = og_df_norm.sample(2*num_amostra, random_state=42)\n",
    "\n",
    "# todas as linhas\n",
    "X_pre = df_pre.loc[:,cols]  \n",
    "y_pre = df_pre[classe].iloc[:]\n",
    "X_pre_train, X_pre_test, y_pre_train, y_pre_test= train_test_split(X_pre, y_pre, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "X_norm = df_norm.loc[:,cols]\n",
    "y_norm = df_norm[classe].iloc[:]\n",
    "X_norm_train, X_norm_test, y_norm_train, y_norm_test= train_test_split(X_norm, y_norm, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "source": [
    "## KKN\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "\n",
    "knn_pre = []\n",
    "knn_norm = []\n",
    "dist = [\"euclidean\",\"manhattan\"]\n",
    "for d in dist:\n",
    "    for i in range(3,12,2):\n",
    "        neigh = KNeighborsClassifier(n_neighbors=i, metric=d, n_jobs=-1)\n",
    "        knn_pre.append({\"knn\": neigh.fit(X_pre_train,y_pre_train), \"dist\":d,\"k\":i})\n",
    "        knn_norm.append({\"knn\": neigh.fit(X_norm_train,y_norm_train), \"dist\":d,\"k\":i})\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Cross-validation do KNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conjunto antes do Pré-Processamento\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2993\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       0.50      0.50      0.50      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2993\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       0.50      0.50      0.50      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2993\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       0.50      0.50      0.50      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2993\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       0.50      0.50      0.50      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2993\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           1.00      3000\n",
      "   macro avg       0.50      0.50      0.50      3000\n",
      "weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.11      0.21      2993\n",
      "           1       0.00      1.00      0.01         7\n",
      "\n",
      "    accuracy                           0.12      3000\n",
      "   macro avg       0.50      0.56      0.11      3000\n",
      "weighted avg       1.00      0.12      0.20      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18      2993\n",
      "           1       0.00      1.00      0.01         7\n",
      "\n",
      "    accuracy                           0.10      3000\n",
      "   macro avg       0.50      0.55      0.09      3000\n",
      "weighted avg       1.00      0.10      0.18      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.16      2993\n",
      "           1       0.00      1.00      0.01         7\n",
      "\n",
      "    accuracy                           0.09      3000\n",
      "   macro avg       0.50      0.54      0.09      3000\n",
      "weighted avg       1.00      0.09      0.16      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.15      2993\n",
      "           1       0.00      1.00      0.01         7\n",
      "\n",
      "    accuracy                           0.08      3000\n",
      "   macro avg       0.50      0.54      0.08      3000\n",
      "weighted avg       1.00      0.08      0.15      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.14      2993\n",
      "           1       0.00      1.00      0.01         7\n",
      "\n",
      "    accuracy                           0.08      3000\n",
      "   macro avg       0.50      0.54      0.07      3000\n",
      "weighted avg       1.00      0.08      0.14      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Conjunto antes do Pré-Processamento\")\n",
    "for knn in knn_pre:\n",
    "    y_pred = knn[\"knn\"].predict(X_pre_test)\n",
    "    cr = classification_report(y_pre_test,y_pred,target_names=[\"0\",\"1\"],zero_division=0)\n",
    "    print(cr)\n",
    "    # scores = cross_val_score(knn[\"knn\"],X_pre_test,y=y_pre_test,cv=10,n_jobs=-1)\n",
    "    # print(f\"K: {i} | Distância: {d} | Acurácia {scores.mean():.6f} com D.P. de {scores.std():.6f}\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "## MLP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "range_mlp = range(1,3)\n",
    "\n",
    "mlp_pre = []\n",
    "mlp_norm = []\n",
    "for n_layer in range_mlp:\n",
    "    clf = MLPClassifier(solver='adam',alpha=1e-5,hidden_layer_sizes=(n_layer,), random_state=42)\n",
    "    mlp_pre.append({\"mlp\": clf.fit(X_pre_train,y_pre_train), \"hidden\":n_layer})\n",
    "    mlp_norm.append({\"mlp\": clf.fit(X_norm_train,y_norm_train), \"hidden\":n_layer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for mlp in mlp_pre:\n",
    "    print(mlp[\"mlp\"].predict(X_pre_test))\n",
    "#     score = mlp[\"mlp\"].score(X_pre_test,y_pre_test)\n",
    "#     print(f\"Hidden layers: {mlp['hidden']} | Acurácia de {score.mean():.6f} com DP de {score.std():.6f}\")\n",
    "# print(\"\\nConjunto Normalizado\")\n",
    "# for mlp in mlp_norm:\n",
    "#     score = mlp[\"mlp\"].score(X_norm_test,y_norm_test)\n",
    "#     print(f\"Hidden layers: {mlp['hidden']} | Acurácia de {score.mean():.6f} com DP de {score.std():.6f}\")"
   ]
  },
  {
   "source": [
    "## Cross-validation do MLP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conjunto Pré-Processamento\n[1. 1. 1. ... 1. 1. 1.]\n[0 0 0 ... 0 0 0]\nHidden layers: 1 | Acurácia de 0.493833 com DP de 0.000000\n[0. 0. 0. ... 0. 0. 0.]\n[0 0 0 ... 0 0 0]\nHidden layers: 2 | Acurácia de 0.493833 com DP de 0.000000\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# print(\"Conjunto Pré-Processamento\")\n",
    "# for mlp in mlp_pre:\n",
    "#     y_pred = mlp[\"mlp\"].predict(X_pre_test)\n",
    "#     print(y_pred)\n",
    "#     print(y_pre_test.values)\n",
    "#     print(f\"Hidden layers: {mlp['hidden']} | Acurácia de {score.mean():.6f} com DP de {score.std():.6f}\")\n",
    "# # print(\"\\nConjunto Normalizado\")\n",
    "# # for mlp in mlp_norm:\n",
    "# #     score = mlp[\"mlp\"].score(X_norm_test,y_norm_test)\n",
    "# #     print(f\"Hidden layers: {mlp['hidden']} | Acurácia de {score.mean():.6f} com DP de {score.std():.6f}\")"
   ]
  }
 ]
}